{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sys.path.append(\"/home/sunzehui/GeneNet/\")\n",
    "from data_utils.pathways.reactome import Reactome, ReactomeNetwork\n",
    "from config_path import *\n",
    "import data_utils.data_access\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Activation, Dense, Softmax, Conv1D, Layer, Conv2D\n",
    "from tensorflow.keras.activations import relu, sigmoid, softmax, tanh\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"data_reader\n",
    "\n",
    "Returns:\n",
    "    _type_: _description_\n",
    "\"\"\"\n",
    "\n",
    "# Path Define\n",
    "data_path = DATA_PATH\n",
    "processed_path = join(DATA_PATH, 'processed')\n",
    "cached_data = {}\n",
    "response_filename = join(DATA_PATH, 'processed/response.csv')\n",
    "cnv_burden_filename = join(DATA_PATH, 'processed/CNV_burden.csv')\n",
    "gene_important_mutations_only = join(DATA_PATH, \"processed/somatic_mutations_important_only.csv\")\n",
    "cnv_filename = join(DATA_PATH, \"processed/CNV.csv\")\n",
    "# gene_final_no_silent_no_intron = join(DATA_PATH, \"processed/somatic_mutations_important_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, selected_genes=None):\n",
    "    filename = join(processed_path, filename)\n",
    "    logging.info(f'loading GeneNet_data from {filename},')\n",
    "    if filename in cached_data:\n",
    "        logging.info('loading from memory cached_data')\n",
    "        data = cached_data[filename]\n",
    "    else:\n",
    "        data = pd.read_csv(filename, index_col=0)\n",
    "        cached_data[filename] = data\n",
    "    logging.info(f\"The loaded dataframe's shape is {data.shape}\")\n",
    "\n",
    "    if 'response' in cached_data:\n",
    "        logging.info('loading from memory cached_data')\n",
    "        labels = cached_data['response']\n",
    "    else:\n",
    "        labels = get_response()\n",
    "        cached_data['response'] = labels\n",
    "\n",
    "    # join with the labels\n",
    "    _all = data.join(labels, how='inner')\n",
    "    # 去除response=NA\n",
    "    _all = _all[~_all['response'].isnull()]\n",
    "\n",
    "    response = _all['response']\n",
    "    samples = _all.index\n",
    "\n",
    "    del _all['response']\n",
    "    x = _all\n",
    "    genes = _all.columns\n",
    "\n",
    "    if selected_genes is not None:\n",
    "        intersect = set.intersection(set(genes), selected_genes)\n",
    "        if len(intersect) < len(selected_genes):\n",
    "            # raise Exception('wrong gene')\n",
    "            logging.warning('some genes dont exist in the original GeneNet_data set')\n",
    "        x = x.loc[:, list(intersect)]\n",
    "        genes = intersect\n",
    "    logging.info('loaded GeneNet_data %d samples, %d variables, %d responses ' % (x.shape[0], x.shape[1], response.shape[0]))\n",
    "    logging.info(len(genes))\n",
    "    return x, response, samples, genes\n",
    "\n",
    "# Load Tumor mutation burden\n",
    "def load_TMB(filename=gene_final_no_silent_no_intron):\n",
    "    x, response, samples, genes = load_data(filename)\n",
    "    x = np.sum(x, axis=1)\n",
    "    x = np.array(x)\n",
    "    x = np.log(1. + x)\n",
    "    n = x.shape[0]\n",
    "    response = response.values.reshape((n, 1))\n",
    "    samples = np.array(samples)\n",
    "    cols = np.array(['TMB'])\n",
    "    return x, response, samples, cols\n",
    "\n",
    "\n",
    "def load_CNV_burden(filename=gene_final_no_silent_no_intron):\n",
    "    x, response, samples, genes = load_data(filename)\n",
    "    x = np.sum(x, axis=1)\n",
    "    x = np.array(x)\n",
    "    x = np.log(1. + x)\n",
    "    n = x.shape[0]\n",
    "    response = response.values.reshape((n, 1))\n",
    "    samples = np.array(samples)\n",
    "    cols = np.array(['TMB'])\n",
    "    return x, response, samples, cols\n",
    "\n",
    "\n",
    "def load_data_type(data_type='gene', cnv_levels=5, cnv_filter_single_event=True, mut_binary=False, selected_genes=None):\n",
    "    logging.info('loading {}'.format(data_type))\n",
    "    if data_type == 'TMB':\n",
    "        x, response, info, genes = load_TMB(gene_important_mutations_only)\n",
    "\n",
    "\n",
    "    if data_type == 'mut_important':\n",
    "        x, response, info, genes = load_data(gene_important_mutations_only, selected_genes)\n",
    "        if mut_binary:\n",
    "            logging.info('mut_binary = True')\n",
    "            x[x > 1.] = 1.\n",
    "\n",
    "    if data_type == 'cnv':\n",
    "        x, response, info, genes = load_data(cnv_filename, selected_genes)\n",
    "        if cnv_levels == 3:\n",
    "            logging.info('cnv_levels = 3')\n",
    "            # remove single amplification and single delteion, they are usually noisey\n",
    "            if cnv_levels == 3:\n",
    "                if cnv_filter_single_event:\n",
    "                    x[x == -1.] = 0.0\n",
    "                    x[x == -2.] = 1.0\n",
    "                    x[x == 1.] = 0.0\n",
    "                    x[x == 2.] = 1.0\n",
    "                else:\n",
    "                    x[x < 0.] = -1.\n",
    "                    x[x > 0.] = 1.\n",
    "\n",
    "    if data_type == 'cnv_del':\n",
    "        x, response, info, genes = load_data(cnv_filename, selected_genes)\n",
    "        x[x >= 0.0] = 0.\n",
    "        if cnv_levels == 3:\n",
    "            if cnv_filter_single_event:\n",
    "                x[x == -1.] = 0.0\n",
    "                x[x == -2.] = 1.0\n",
    "            else:\n",
    "                x[x < 0.0] = 1.0\n",
    "        else:  # cnv == 5 , use everything\n",
    "            x[x == -1.] = 0.5\n",
    "            x[x == -2.] = 1.0\n",
    "\n",
    "    if data_type == 'cnv_amp':\n",
    "        x, response, info, genes = load_data(cnv_filename, selected_genes)\n",
    "        x[x <= 0.0] = 0.\n",
    "        if cnv_levels == 3:\n",
    "            if cnv_filter_single_event:\n",
    "                x[x == 1.0] = 0.0\n",
    "                x[x == 2.0] = 1.0\n",
    "            else:\n",
    "                x[x > 0.0] = 1.0\n",
    "        else:  # cnv == 5 , use everything\n",
    "            x[x == 1.] = 0.5\n",
    "            x[x == 2.] = 1.0\n",
    "\n",
    "    if data_type == 'cnv_single_del':\n",
    "        x, response, info, genes = load_data(cnv_filename, selected_genes)\n",
    "        x[x == -1.] = 1.0\n",
    "        x[x != -1.] = 0.0\n",
    "    if data_type == 'cnv_single_amp':\n",
    "        x, response, info, genes = load_data(cnv_filename, selected_genes)\n",
    "        x[x == 1.] = 1.0\n",
    "        x[x != 1.] = 0.0\n",
    "    if data_type == 'cnv_high_amp':\n",
    "        x, response, info, genes = load_data(cnv_filename, selected_genes)\n",
    "        x[x == 2.] = 1.0\n",
    "        x[x != 2.] = 0.0\n",
    "    if data_type == 'cnv_deep_del':\n",
    "        x, response, info, genes = load_data(cnv_filename, selected_genes)\n",
    "        x[x == -2.] = 1.0\n",
    "        x[x != -2.] = 0.0\n",
    "\n",
    "    if data_type == 'gene_expression':\n",
    "        x, response, info, genes = load_data(gene_expression, selected_genes)\n",
    "\n",
    "    if data_type == 'fusions':\n",
    "        x, response, info, genes = load_data(fusions_filename, None)\n",
    "\n",
    "    if data_type == 'cnv_burden':\n",
    "        x, response, info, genes = load_data(cnv_burden_filename, None)\n",
    "\n",
    "    if data_type == 'fusion_genes':\n",
    "        x, response, info, genes = load_data(fusions_genes_filename, selected_genes)\n",
    "\n",
    "    return x, response, info, genes\n",
    "\n",
    "\n",
    "def get_response():\n",
    "    logging.info(f'loading response from {response_filename}')\n",
    "    labels = pd.read_csv(join(processed_path, response_filename))\n",
    "    labels = labels.set_index('id')\n",
    "    return labels\n",
    "\n",
    "\n",
    "# complete_features: make sure all the data_types have the same set of features_processing (genes)\n",
    "def combine(x_list, y_list, rows_list, cols_list, data_type_list, combine_type, use_coding_genes_only=False):\n",
    "    cols_list_set = [set(list(c)) for c in cols_list]\n",
    "\n",
    "    if combine_type == 'intersection':\n",
    "        cols = set.intersection(*cols_list_set)\n",
    "    else:\n",
    "        cols = set.union(*cols_list_set)\n",
    "\n",
    "    if use_coding_genes_only:\n",
    "        f = join(data_path, 'genes/HUGO_genes/protein-coding_gene_with_coordinate_minimal.txt')\n",
    "        coding_genes_df = pd.read_csv(f, sep='\\t', header=None)\n",
    "        coding_genes_df.columns = ['chr', 'start', 'end', 'name']\n",
    "        coding_genes = set(coding_genes_df['name'].unique())\n",
    "        cols = cols.intersection(coding_genes)\n",
    "\n",
    "    # the unique (super) set of genes\n",
    "    all_cols = list(cols)\n",
    "\n",
    "    all_cols_df = pd.DataFrame(index=all_cols)  # Empty dataframe in which index is genes\n",
    "\n",
    "    df_list = []\n",
    "    for x, y, r, c in zip(x_list, y_list, rows_list, cols_list):\n",
    "        df = pd.DataFrame(x, columns=c, index=r)  # cols are genes, index is id, right join instances\n",
    "        df = df.T.join(all_cols_df, how='right')  # df.T index are genes, cols are ids\n",
    "        df = df.T  # index is id, cols are genes\n",
    "        # print(f\"df.columns are {df.columns}, df.index is {df.index}\")\n",
    "        df = df.fillna(0)  # fill it with 0\n",
    "        df_list.append(df)\n",
    "    #  这一步的目的是为了将各种不同类型的数据整合在一起，形成一个以index=gene, data_type为multi-index，\n",
    "    all_data = pd.concat(df_list, keys=data_type_list, join='inner', axis=1, )\n",
    "\n",
    "    # 整合完毕之后形成一个columns为多重索引[data_type, gene_name], 在这之后用swaplevel函数将其倒换\n",
    "    # put genes on the first level and then the GeneNet_data type\n",
    "    all_data = all_data.swaplevel(i=0, j=1, axis=1)\n",
    "\n",
    "    # order the columns based on genes, 按照基因字母序进行列排序\n",
    "    order = all_data.columns.levels[0]  # 选取columns的多重索引的level=0的索引，即gene\n",
    "    all_data = all_data.reindex(columns=order, level=0)\n",
    "    # print(f\"df.columns are {all_data.columns}, df.index is {all_data.index}\")\n",
    "\n",
    "    x = all_data.values  # 去除掉表头等标签属性，只提取纯数据\n",
    "\n",
    "    # prepare response\n",
    "    reordering_df = pd.DataFrame(index=all_data.index)\n",
    "    y = reordering_df.join(y, how='left')\n",
    "\n",
    "    # print(f\"df.columns are {y.columns}, df.index is {y.index}\")\n",
    "\n",
    "    y = y.values\n",
    "    cols = all_data.columns  # [gene, data_type]\n",
    "    rows = all_data.index  # [id]\n",
    "    logging.info(\n",
    "        'After combining, loaded GeneNet_data %d samples, %d variables, %d responses ' % (x.shape[0], x.shape[1], y.shape[0])\n",
    "    )\n",
    "\n",
    "    return x, y, rows, cols\n",
    "\n",
    "\n",
    "def split_cnv(x_df):\n",
    "    genes = x_df.columns.levels[0]\n",
    "    x_df.rename(columns={'cnv': 'CNA_amplification'}, inplace=True)\n",
    "    for g in genes:\n",
    "        x_df[g, 'CNA_deletion'] = x_df[g, 'CNA_amplification'].replace({-1.0: 0.5, -2.0: 1.0})\n",
    "        x_df[g, 'CNA_amplification'] = x_df[g, 'CNA_amplification'].replace({1.0: 0.5, 2.0: 1.0})\n",
    "    x_df = x_df.reindex(columns=genes, level=0)\n",
    "    return x_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataClass:\n",
    "\n",
    "    def __init__(self, data_type='mut', account_for_data_type=None, cnv_levels=5,\n",
    "                 cnv_filter_single_event=True, mut_binary=False,\n",
    "                 selected_genes=None, combine_type='intersection',\n",
    "                 use_coding_genes_only=False, drop_AR=False,\n",
    "                 balanced_data=False, cnv_split=False,\n",
    "                 shuffle=False, selected_samples=None, training_split=0):\n",
    "\n",
    "        self.training_split = training_split\n",
    "        if selected_genes is not None:\n",
    "            if type(selected_genes) == list:\n",
    "                # list of genes\n",
    "                selected_genes = selected_genes\n",
    "            else:\n",
    "                # file that will be used to load list of genes\n",
    "                selected_genes_file = join(data_path, 'genes')\n",
    "                selected_genes_file = join(selected_genes_file, selected_genes)\n",
    "                df = pd.read_csv(selected_genes_file, header=0)\n",
    "                selected_genes = list(df['genes'])\n",
    "\n",
    "        if isinstance(data_type, list):\n",
    "            x_list = []\n",
    "            y_list = []\n",
    "            rows_list = []\n",
    "            cols_list = []\n",
    "\n",
    "            for t in data_type:\n",
    "                x, y, rows, cols = load_data_type(t, cnv_levels, cnv_filter_single_event, mut_binary, selected_genes)\n",
    "                x_list.append(x), y_list.append(y), rows_list.append(rows), cols_list.append(cols)\n",
    "            x, y, rows, cols = combine(x_list, y_list, rows_list, cols_list, data_type, combine_type,\n",
    "                                       use_coding_genes_only)\n",
    "            x = pd.DataFrame(x, columns=cols)\n",
    "        else:\n",
    "            x, y, rows, cols = load_data_type(data_type, cnv_levels, cnv_filter_single_event, mut_binary,\n",
    "                                              selected_genes)\n",
    "\n",
    "        if drop_AR:\n",
    "\n",
    "            data_types = x.columns.levels[1].unique()\n",
    "            ind = True\n",
    "            if 'cnv' in data_types:\n",
    "                ind = x[('AR', 'cnv')] <= 0.\n",
    "            elif 'cnv_amp' in data_types:\n",
    "                ind = x[('AR', 'cnv_amp')] <= 0.\n",
    "\n",
    "            if 'mut_important' in data_types:\n",
    "                ind2 = (x[('AR', 'mut_important')] < 1.)\n",
    "                ind = ind & ind2\n",
    "            x = x.loc[ind,]\n",
    "            y = y[ind]\n",
    "            rows = rows[ind]\n",
    "\n",
    "        if cnv_split:\n",
    "            x = split_cnv(x)\n",
    "\n",
    "        if type(x) == pd.DataFrame:\n",
    "            x = x.values\n",
    "\n",
    "        if balanced_data:\n",
    "            pos_ind = np.where(y == 1.)[0]\n",
    "            neg_ind = np.where(y == 0.)[0]\n",
    "\n",
    "            n_pos = pos_ind.shape[0]\n",
    "            n_neg = neg_ind.shape[0]\n",
    "            n = min(n_pos, n_neg)\n",
    "\n",
    "            pos_ind = np.random.choice(pos_ind, size=n, replace=False)\n",
    "            neg_ind = np.random.choice(neg_ind, size=n, replace=False)\n",
    "\n",
    "            ind = np.sort(np.concatenate([pos_ind, neg_ind]))\n",
    "\n",
    "            y = y[ind]\n",
    "            x = x[ind,]\n",
    "            rows = rows[ind]\n",
    "\n",
    "        if shuffle:\n",
    "            n = x.shape[0]\n",
    "            ind = np.arange(n)\n",
    "            np.random.shuffle(ind)\n",
    "            x = x[ind, :]\n",
    "            y = y[ind, :]\n",
    "            rows = rows[ind]\n",
    "\n",
    "        if account_for_data_type is not None:\n",
    "            x_genomics = pd.DataFrame(x, columns=cols, index=rows)\n",
    "            y_genomics = pd.DataFrame(y, index=rows, columns=['response'])\n",
    "            x_list = []\n",
    "            y_list = []\n",
    "            rows_list = []\n",
    "            cols_list = []\n",
    "            for t in account_for_data_type:\n",
    "                x_, y_, rows_, cols_ = load_data_type(t, cnv_levels, cnv_filter_single_event, mut_binary,\n",
    "                                                      selected_genes)\n",
    "                x_df = pd.DataFrame(x_, columns=cols_, index=rows_)\n",
    "                x_list.append(x_df), y_list.append(y_), rows_list.append(rows_), cols_list.append(cols_)\n",
    "\n",
    "            x_account_for = pd.concat(x_list, keys=account_for_data_type, join='inner', axis=1)\n",
    "            x_all = pd.concat([x_genomics, x_account_for], keys=['genomics', 'account_for'], join='inner', axis=1)\n",
    "\n",
    "            common_samples = set(rows).intersection(x_all.index)\n",
    "            x_all = x_all.loc[list(common_samples), :]\n",
    "            y = y_genomics.loc[list(common_samples), :]\n",
    "\n",
    "            y = y['response'].values\n",
    "            x = x_all.values\n",
    "            cols = x_all.columns\n",
    "            rows = x_all.index\n",
    "\n",
    "        if selected_samples is not None:\n",
    "            selected_samples_file = join(processed_path, selected_samples)\n",
    "            df = pd.read_csv(selected_samples_file, header=0)\n",
    "            selected_samples_list = list(df['Tumor_Sample_Barcode'])\n",
    "\n",
    "            x = pd.DataFrame(x, columns=cols, index=rows)\n",
    "            y = pd.DataFrame(y, index=rows, columns=['response'])\n",
    "\n",
    "            x = x.loc[selected_samples_list, :]\n",
    "            y = y.loc[selected_samples_list, :]\n",
    "            rows = x.index\n",
    "            cols = x.columns\n",
    "            y = y['response'].values\n",
    "            x = x.values\n",
    "\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.info = rows\n",
    "        self.columns = cols\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.x, self.y, self.info, self.columns\n",
    "\n",
    "    def get_train_validate_test(self):\n",
    "        info = self.info\n",
    "        x = self.x\n",
    "        y = self.y\n",
    "        columns = self.columns\n",
    "        splits_path = join(DATA_PATH, 'splits')\n",
    "\n",
    "        training_file = 'training_set_{}.csv'.format(self.training_split)\n",
    "        training_set = pd.read_csv(join(splits_path, training_file))\n",
    "\n",
    "        validation_set = pd.read_csv(join(splits_path, 'validation_set.csv'))\n",
    "        testing_set = pd.read_csv(join(splits_path, 'test_set.csv'))\n",
    "\n",
    "        info_train = list(set(info).intersection(training_set.id))\n",
    "        info_validate = list(set(info).intersection(validation_set.id))\n",
    "        info_test = list(set(info).intersection(testing_set.id))\n",
    "\n",
    "        ind_train = info.isin(info_train)\n",
    "        ind_validate = info.isin(info_validate)\n",
    "        ind_test = info.isin(info_test)\n",
    "\n",
    "        x_train = x[ind_train]\n",
    "        x_test = x[ind_test]\n",
    "        x_validate = x[ind_validate]\n",
    "\n",
    "        y_train = y[ind_train]\n",
    "        y_test = y[ind_test]\n",
    "        y_validate = y[ind_validate]\n",
    "\n",
    "        info_train = info[ind_train]\n",
    "        info_test = info[ind_test]\n",
    "        info_validate = info[ind_validate]\n",
    "\n",
    "        return x_train, x_validate, x_test, y_train, y_validate, y_test, info_train.copy(), info_validate, info_test.copy(), columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected genes are in `RefSeq` collapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:some genes dont exist in the original GeneNet_data set\n",
      "WARNING:root:some genes dont exist in the original GeneNet_data set\n",
      "WARNING:root:some genes dont exist in the original GeneNet_data set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1011, 50698) (1011,) 50698 1011\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"/home/sunzehui/GeneNet/\")\n",
    "from data_utils.data_access import Data\n",
    "\n",
    "selected_genes = 'selected_genes.csv'\n",
    "selected_samples = 'samples_with_fusion_data.csv'\n",
    "data_params = {'id': 'ALL', 'type': 'data_processor',\n",
    "               'params': {\n",
    "                   'data_type': ['mut_important', 'cnv_del', 'cnv_amp'],\n",
    "                   'account_for_data_type': ['TMB'],\n",
    "                   'drop_AR': False,\n",
    "                   'cnv_levels': 3,\n",
    "                   'mut_binary': False,\n",
    "                   'balanced_data': False,\n",
    "                   'combine_type': 'union',  # intersection\n",
    "                   'use_coding_genes_only': False,\n",
    "                   'selected_genes': selected_genes,\n",
    "                   'selected_samples': None,\n",
    "                   'training_split': 0,\n",
    "               }\n",
    "               }\n",
    "\n",
    "data_adapter = Data(**data_params)\n",
    "x, y, barcode, columns = data_adapter.get_data()\n",
    "\n",
    "print(x.shape, y.shape, len(columns), len(barcode))\n",
    "x, y, info, columns = data_adapter.get_data()\n",
    "x_df = pd.DataFrame(x, columns=columns, index=info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df['genomics'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = list(set(i[0] for i in x_df['genomics'].columns))\n",
    "response = get_response().loc[x_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = x_df.reindex(index = response.index)\n",
    "\n",
    "mut_important = pd.concat([x_df['genomics', i, 'mut_important'] for i in genes], axis = 1).values\n",
    "cnv_amp = pd.concat([x_df['genomics', i, 'cnv_amp'] for i in genes], axis = 1).values\n",
    "cnv_del = pd.concat([x_df['genomics', i, 'cnv_del'] for i in genes], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1011, 16899)\n"
     ]
    }
   ],
   "source": [
    "print(cnv_amp.shape) # number_sample * dim * channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1011, 3, 16899)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.array([mut_important, cnv_amp, cnv_del]).transpose(1, 0, 2)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 13:04:11.236785: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-31 13:04:11.238001: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-31 13:04:11.241419: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices((train_data, response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beta-VAE Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2911161097.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [9]\u001b[0;36m\u001b[0m\n\u001b[0;31m    class decoder(tf.keras.layers.Layer):\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class encoder(tf.keras.Model):\n",
    "    def __init__(self, activation = 'relu', weight_initializer = None, weight_regularizer = None):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        if(weight_initializer == 'relu'):\n",
    "            self.activation = Activation(relu)\n",
    "        else:\n",
    "            self.activation = Activation(tanh)\n",
    "        self.w_init = weight_initializer\n",
    "        self.w_regularizer = weight_regularizer\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "       self.input = Input(shape = (32,)) \n",
    "        \n",
    "    def call(self):\n",
    "        \n",
    "    \n",
    "    \n",
    "class decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, trainable=True, name=None, dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d41b3e66ab4053a365be12b1f0ec52700f833eebdee548abd3d6dad6adc98e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
